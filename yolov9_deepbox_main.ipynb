{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'video5'\n",
    "input_file_name = f'video/{video_name}.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kalman_tracking_deepbox.sort import Sort\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_file_name = f\"video/{video_name}.mp4\"\n",
    "output_file_name = f\"output/{video_name}_tracked.mp4\"\n",
    "output_state_file_name = f\"output/{video_name}_states.json\"\n",
    "\n",
    "sort = Sort(max_age=30, iou_threshold=0.1, zc=750)\n",
    "\n",
    "cap = cv2.VideoCapture(input_file_name)\n",
    "with open(f'output/{video_name}_yolov9.json') as f:\n",
    "    detections = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "state_rotations = []\n",
    "color_mapping = {}\n",
    "try:\n",
    "    while proc_frames < len(detections):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        detection = detections[proc_frames]\n",
    "        detection_converted = []\n",
    "        for Z in detection:\n",
    "            detection_converted.append([Z[0]-Z[2]/2, Z[1]-Z[3]/2, Z[0]+Z[2]/2, Z[1]+Z[3]/2, Z[4]])\n",
    "        detection_converted = np.array(detection_converted)\n",
    "\n",
    "        # tracking\n",
    "        if len(detection_converted) > 0:\n",
    "            Zs, Xs = sort.update(detection_converted)\n",
    "        else:\n",
    "            Zs, Xs = sort.update(np.empty((0, 4)))\n",
    "\n",
    "        temp = []\n",
    "        for (Z, X) in zip(Zs, Xs):\n",
    "            vehicle_id = int(Z[-1])\n",
    "            if vehicle_id not in color_mapping:\n",
    "                bounding_rect = im[int(Z[1]):int(Z[3]), int(Z[0]):int(Z[2])]\n",
    "                try:\n",
    "                    bgr_color = np.average(np.average(bounding_rect, axis=0), axis=0)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "\n",
    "                hsv_color = cv2.cvtColor(np.array([[bgr_color]]).astype(np.uint8), cv2.COLOR_BGR2HSV)\n",
    "                hsv_color[:, :, 1] = 200\n",
    "                bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)[0, 0]\n",
    "\n",
    "                rgb_color = [int(bgr_color[2]), int(bgr_color[1]), int(bgr_color[0])]\n",
    "                color_mapping[vehicle_id] = rgb_color\n",
    "\n",
    "            temp.append(X.tolist() + [Z[0], Z[1], Z[2], Z[3], int(Z[-1]), color_mapping[vehicle_id]])\n",
    "            cv2.rectangle(im, (int(Z[0]), int(Z[1])), (int(Z[2]), int(Z[3])), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{int(Z[6])} ({int(X[0])},0,{int(X[2])},{int(X[3])})', (int((Z[0] + Z[2])//2), int((Z[1] + Z[3])//2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        state_rotations.append(temp)\n",
    "\n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    import traceback\n",
    "    print(traceback.format_exc())\n",
    "finally:\n",
    "    out.release()\n",
    "    cap.release()\n",
    "\n",
    "with open(output_state_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump({ \"states\": state_rotations }, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -i output/video5_tracked.mp4 -i output/video5_audio.mp3 -c:v libx264 -c:a copy -map 0:v:0 -map 1:a:0 output/video5_tracked_audio.mp4 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPLVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 74057.302578\n",
      "         Iterations: 3\n",
      "         Function evaluations: 684\n",
      "         Gradient evaluations: 56\n",
      "time: 0.13432860374450684\n",
      "alpha 1.1739144324584667\n",
      "beta 0.6012194508534535\n",
      "gamma 0.9999424872417098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1698: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_cg(f, x0, args, fprime, callback=callback, **opts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-28.79344749,  15.88861275],\n",
       "       [ 40.50342178,   7.74950457],\n",
       "       [ -7.06363434, -13.97268919],\n",
       "       [ -4.64632087,  -9.66539711]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mygplvm.reconstruction import Reconstruction\n",
    "\n",
    "sdfs = []\n",
    "sdf_names = ['Jeep', 'Pickup', 'Sedan', 'Suv']\n",
    "voxel_resolution = 64\n",
    "dct_resolution = 25\n",
    "for name in sdf_names:\n",
    "    sdfs.append(np.load(f'./mygplvm/objs3/{name}_SDF_{voxel_resolution}x{voxel_resolution}x{voxel_resolution}.npy'))\n",
    "\n",
    "rec = Reconstruction(voxel_resolution=voxel_resolution, dct_resolution=dct_resolution)\n",
    "rec.fit_from_sdf(sdfs=sdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPLVM Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mygplvm.reconstruction3 import Reconstruction3\n",
    "from road_segmentation.road_segmentation import RoadSegmentation\n",
    "\n",
    "road_segmentation = RoadSegmentation()\n",
    "rec3 = Reconstruction3(rec.gplvm, voxel_resolution, dct_resolution)\n",
    "\n",
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, sin, pi, atan\n",
    "import json\n",
    "import cv2\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "generic_mesh = rec.reconstruct_from_x([ -4.6463161 ,  -9.66539711])\n",
    "\n",
    "output_file_name = f'output/{video_name}_reconstructed.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(30)\n",
    "width, height = (\n",
    "    int(1280),\n",
    "    int(720)\n",
    ")\n",
    "cap = cv2.VideoCapture(input_file_name)\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "with open(f'output/{video_name}_states.json') as f:\n",
    "    state_rotations = json.load(f)['states']\n",
    "\n",
    "# plane_dimension = [70, 0.01, 2000]\n",
    "# planes = [trimesh.creation.box(extents=plane_dimension) for i in range(11)]\n",
    "# for i, plane in enumerate(planes):\n",
    "#     abs_offset = abs(i - len(planes)//2)\n",
    "#     plane.visual.face_colors = [75 + 15*abs_offset, 75 + 15*abs_offset, 75 + 15*abs_offset, 255]\n",
    "\n",
    "r = pyrender.OffscreenRenderer(1280, 720)\n",
    "try:\n",
    "    proc_frames = 0\n",
    "    while proc_frames < len(state_rotations):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if proc_frames == 1:\n",
    "            break\n",
    "        \n",
    "        state = state_rotations[proc_frames]\n",
    "        scene = pyrender.Scene(ambient_light=[0.8, 0.8, 0.8], bg_color=[50, 50, 50])\n",
    "        state_multiplier = 25\n",
    "\n",
    "        # my vehicle\n",
    "        car_tmesh = rec.reconstruct_from_x([ -4.6463161 ,  -9.66539711])\n",
    "        car_tmesh.visual.vertex_colors = [255, 0, 0, 255]\n",
    "        car_pymesh = pyrender.Mesh.from_trimesh(car_tmesh, smooth=False)\n",
    "        scene.add(car_pymesh, pose=np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 20],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ]))\n",
    "\n",
    "        # shape reconstruction\n",
    "        for vehicle in state:\n",
    "            xy = np.asarray(vehicle[11:15], dtype=int)\n",
    "            yaw_d = np.deg2rad(vehicle[3])\n",
    "            # if xy[1] >= xy[3] or xy[0] >= xy[2]: continue\n",
    "\n",
    "            # mc_mesh = rec3.predict(frame[xy[1]:xy[3], xy[0]:xy[2]], yaw_d)\n",
    "            # if mc_mesh is None: continue\n",
    "            # mc_mesh.visual.vertex_colors = vehicle[16] + [255]\n",
    "\n",
    "            # mesh_pyrender = pyrender.Mesh.from_trimesh(mc_mesh, smooth=False)\n",
    "            generic_mesh.visual.vertex_colors = [150, 150, 150, 255]\n",
    "            mesh_pyrender = pyrender.Mesh.from_trimesh(generic_mesh, smooth=False)\n",
    "            if vehicle[0] < 0:\n",
    "                yaw = yaw_d + atan(vehicle[0] / vehicle[2])\n",
    "            else:\n",
    "                yaw = yaw_d - atan(vehicle[0] / vehicle[2])\n",
    "            # yaw = yaw_d\n",
    "            mesh_pose = np.array([\n",
    "                [cos(yaw), 0, sin(yaw), vehicle[0] * state_multiplier],\n",
    "                [0, 1, 0, 20],\n",
    "                [-sin(yaw), 0, cos(yaw), -vehicle[2] * state_multiplier * 0.75],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            scene.add(mesh_pyrender, pose=mesh_pose)\n",
    "\n",
    "        # road reconstruction\n",
    "        road_mask = road_segmentation.predict(frame)\n",
    "        road_tmesh = road_segmentation.reconstruct(road_mask)\n",
    "        road_tmesh.visual.vertex_colors = [240, 240, 240, 255]\n",
    "        road_pymesh = pyrender.Mesh.from_trimesh(road_tmesh, smooth=False)\n",
    "        road_scale = state_multiplier*1.5\n",
    "        scene.add(road_pymesh, pose=np.array([\n",
    "            [road_scale, 0, 0, 0],\n",
    "            [0, road_scale, 0, 0],\n",
    "            [0, 0, road_scale, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ]))\n",
    "        \n",
    "        # camera and lighting\n",
    "        camera_pitch = -pi/6\n",
    "        camera_pose = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, cos(camera_pitch), -sin(camera_pitch), 150],\n",
    "            [0, sin(camera_pitch), cos(camera_pitch), 150],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        light_pose = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 1000],\n",
    "            [0, 0, 1, -25],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        pl = pyrender.PointLight(color=[1.0, 1.0, 1.0], intensity=1000000)\n",
    "        pc = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1280/720)\n",
    "        scene.add(pl, pose=light_pose)\n",
    "        scene.add(pc, pose=camera_pose)\n",
    "\n",
    "        # # add planes\n",
    "        # for i, plane in enumerate(planes):\n",
    "        #     offset = i - len(planes)//2\n",
    "        #     plane_pyrender = pyrender.Mesh.from_trimesh(plane, smooth=False)\n",
    "        #     mesh_pose = np.array([\n",
    "        #         [1, 0, 0, offset * plane_dimension[0]],\n",
    "        #         [0, 1, 0, 0],\n",
    "        #         [0, 0, 1, -plane_dimension[2]/3],\n",
    "        #         [0, 0, 0, 1]\n",
    "        #     ])\n",
    "        #     scene.add(plane_pyrender, pose=mesh_pose)\n",
    "\n",
    "        color, _ = r.render(scene)\n",
    "        # plt.figure(figsize=(8,8)), plt.imshow(color)\n",
    "        out.write(color)\n",
    "        cv2.imwrite('yolov9.png', color)\n",
    "        \n",
    "        proc_frames += 1\n",
    "\n",
    "        \n",
    "except Exception as error:\n",
    "    import traceback\n",
    "    print(traceback.format_exc())\n",
    "finally:\n",
    "    # Release resource\n",
    "    r.delete()\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -i output/video5_reconstructed.mp4 -i output/video5_audio.mp3 -c:v libx264 -c:a copy -map 0:v:0 -map 1:a:0 output/video5_reconstructed_audio.mp4 -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
