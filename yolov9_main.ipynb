{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'video0'\n",
    "input_file_name = f'video/{video_name}.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing YOLO Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "yolov9_video_name = f'output/{video_name}_yolov9.mp4'\n",
    "\n",
    "# Draw bounding box to video\n",
    "cap = cv2.VideoCapture(input_file_name)\n",
    "with open(f'output/{video_name}_yolov9.json') as f:\n",
    "    detections = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(yolov9_video_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "try:\n",
    "    while proc_frames < len(detections):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        for d in detections[proc_frames]:\n",
    "            cv2.rectangle(im, (int(d[0] - d[2]/2), int(d[1] - d[3]/2)), (int(d[0] + d[2]/2), int(d[1] + d[3]/2)), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{d[5]:.2f}', (int(d[0]), int(d[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    print(error)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -i video/video0.mp4 -f mp3 -ab 192000 -vn output/video0_audio.mp3 -y\n",
    "!ffmpeg -i output/video0_yolov9.mp4 -i output/video0_audio.mp3 -c:v libx264 -c:a copy -map 0:v:0 -map 1:a:0 output/video0_yolov9_audio.mp4 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bryan\\TA\\Integrated\\kalman_tracking_yolov9\\sort.py:75: RuntimeWarning: invalid value encountered in sqrt\n",
      "  w = np.sqrt(x[3] * x[4])\n"
     ]
    }
   ],
   "source": [
    "from kalman_tracking_yolov9.sort import Sort\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_file_name = f\"video/{video_name}.mp4\"\n",
    "output_file_name = f\"output/{video_name}_tracked.mp4\"\n",
    "output_state_file_name = f\"output/{video_name}_states.json\"\n",
    "\n",
    "sort = Sort(max_age=5, iou_threshold=0.3, zc=750)\n",
    "\n",
    "cap = cv2.VideoCapture(input_file_name)\n",
    "with open(f'output/{video_name}_yolov9.json') as f:\n",
    "    detections = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "states = []\n",
    "color_mapping = {}\n",
    "try:\n",
    "    while proc_frames < len(detections):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        d = detections[proc_frames]\n",
    "        d_converted = []\n",
    "        for x in d:\n",
    "            d_converted.append([x[0]-x[2]/2, x[1]-x[3]/2, x[0]+x[2]/2, x[1]+x[3]/2])\n",
    "        d_converted = np.array(d_converted)\n",
    "\n",
    "        # tracking\n",
    "        if len(d_converted) > 0:\n",
    "            xs, xrs = sort.update(d_converted)\n",
    "        else:\n",
    "            xs, xrs = sort.update()\n",
    "\n",
    "        temp = []\n",
    "        for (x, xr) in zip(xs, xrs):\n",
    "            vehicle_id = int(x[-1])\n",
    "            if vehicle_id not in color_mapping:\n",
    "                bounding_rect = im[int(x[1]):int(x[3]), int(x[0]):int(x[2])]\n",
    "                try:\n",
    "                    bgr_color = np.average(np.average(bounding_rect, axis=0), axis=0)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "\n",
    "                hsv_color = cv2.cvtColor(np.array([[bgr_color]]).astype(np.uint8), cv2.COLOR_BGR2HSV)\n",
    "                # if proc_frames == 0:\n",
    "                #     print(hsv_color)\n",
    "                hsv_color[:, :, 1] = 200\n",
    "                # hsv_color[:, :, 1] = np.array(min(hsv_color[:, :, 1] * 1.5, 255)).astype(np.uint8)\n",
    "                # hsv_color[:, :, 2] *= np.array(min(hsv_color[:, :, 2] * 1, 255)).astype(np.uint8)\n",
    "                bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)[0, 0]\n",
    "\n",
    "                rgb_color = [int(bgr_color[2]), int(bgr_color[1]), int(bgr_color[0])]\n",
    "                color_mapping[vehicle_id] = rgb_color\n",
    "\n",
    "            temp.append(xr.tolist() + [int(x[-1]), color_mapping[vehicle_id]])\n",
    "            cv2.rectangle(im, (int(x[0]), int(x[1])), (int(x[2]), int(x[3])), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{int(x[4])} ({int(xr[0])},{int(xr[1])},{int(xr[2])})', (int((x[0] + x[2])//2), int((x[1] + x[3])//2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        states.append(temp)\n",
    "\n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(error.with_traceback())\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "\n",
    "with open(output_state_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump({ \"states\": states }, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -i output/video0_tracked.mp4 -i output/video0_audio.mp3 -c:v libx264 -c:a copy -map 0:v:0 -map 1:a:0 output/video0_tracked_audio.mp4 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPLVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 74057.302578\n",
      "         Iterations: 3\n",
      "         Function evaluations: 732\n",
      "         Gradient evaluations: 60\n",
      "time: 0.15903091430664062\n",
      "alpha 1.173914432451989\n",
      "beta 0.6012194508483061\n",
      "gamma 0.9999424876154688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1698: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_cg(f, x0, args, fprime, callback=callback, **opts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-28.79345703,  15.8886137 ],\n",
       "       [ 40.50338745,   7.74951172],\n",
       "       [ -7.06363434, -13.97269778],\n",
       "       [ -4.64632135,  -9.66540378]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mygplvm.reconstruction import Reconstruction\n",
    "\n",
    "sdfs = []\n",
    "sdf_names = ['Jeep', 'Pickup', 'Sedan', 'Suv']\n",
    "voxel_resolution = 64\n",
    "dct_resolution = 25\n",
    "for name in sdf_names:\n",
    "    sdfs.append(np.load(f'./mygplvm/objs3/{name}_SDF_{voxel_resolution}x{voxel_resolution}x{voxel_resolution}.npy'))\n",
    "\n",
    "rec = Reconstruction(voxel_resolution=voxel_resolution, dct_resolution=dct_resolution)\n",
    "rec.fit_from_sdf(sdfs=sdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPLVM Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, sin, pi, atan\n",
    "import json\n",
    "import cv2\n",
    "import trimesh\n",
    "\n",
    "output_file_name = f'output/{video_name}_reconstructed.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(30)\n",
    "width, height = (\n",
    "    int(1280),\n",
    "    int(720)\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "with open(f'output/{video_name}_states.json') as f:\n",
    "    states = json.load(f)['states']\n",
    "\n",
    "plane_dimension = [70, 0.01, 2000]\n",
    "planes = [trimesh.creation.box(extents=plane_dimension) for i in range(11)]\n",
    "for i, plane in enumerate(planes):\n",
    "    abs_offset = abs(i - len(planes)//2)\n",
    "    plane.visual.face_colors = [75 + 15*abs_offset, 75 + 15*abs_offset, 75 + 15*abs_offset, 255]\n",
    "\n",
    "try:\n",
    "    for i, state in enumerate(states):\n",
    "        scene = pyrender.Scene(ambient_light=[0.6, 0.6, 0.6], bg_color=[1.0, 1.0, 1.0])\n",
    "        state_multiplier = 25\n",
    "        for vehicle in state:\n",
    "            mc_mesh = rec.reconstruct_from_x([ -4.6463161 ,  -9.66539997])\n",
    "            # for facet in mc_mesh.facets:\n",
    "            #     mc_mesh.visual.face_colors[facet] = vehicle[10] + [255]\n",
    "            mc_mesh.visual.vertex_colors = vehicle[10] + [255]\n",
    "\n",
    "            mesh_pyrender = pyrender.Mesh.from_trimesh(mc_mesh, smooth=False)\n",
    "            if abs(vehicle[0]) > 15:\n",
    "                sudut = pi / 2\n",
    "            else:\n",
    "                sudut = 0\n",
    "            try:\n",
    "                sudut += atan(vehicle[5]/vehicle[7])\n",
    "            except:\n",
    "                pass\n",
    "            mesh_pose = np.array([\n",
    "                [cos(sudut), 0, sin(sudut), vehicle[0] * state_multiplier],\n",
    "                [0, 1, 0, 8],\n",
    "                [-sin(sudut), 0, cos(sudut), -vehicle[2] * state_multiplier],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            scene.add(mesh_pyrender, pose=mesh_pose)\n",
    "\n",
    "        camera_pose = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 15],\n",
    "            [0, 0, 1, -80],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        light_pose = np.array([\n",
    "            [1, 0, 0, 62],\n",
    "            [0, 1, 0, 62],\n",
    "            [0, 0, 1, 62],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        pl = pyrender.PointLight(color=[1.0, 1.0, 1.0], intensity=50000)\n",
    "        pc = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1280/720)\n",
    "        scene.add(pl, pose=light_pose)\n",
    "        scene.add(pc, pose=camera_pose)\n",
    "\n",
    "        # add planes\n",
    "        for i, plane in enumerate(planes):\n",
    "            offset = i - len(planes)//2\n",
    "            plane_pyrender = pyrender.Mesh.from_trimesh(plane, smooth=False)\n",
    "            mesh_pose = np.array([\n",
    "                [1, 0, 0, offset * plane_dimension[0]],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, -plane_dimension[2]/3],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            scene.add(plane_pyrender, pose=mesh_pose)\n",
    "\n",
    "        r = pyrender.OffscreenRenderer(1280, 720)\n",
    "        color, _ = r.render(scene)\n",
    "        # plt.figure(figsize=(8,8)), plt.imshow(color)\n",
    "        out.write(color)\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    out.release()\n",
    "    print(error.with_traceback())\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -i output/video0_reconstructed.mp4 -i output/video0_audio.mp3 -c:v libx264 -c:a copy -map 0:v:0 -map 1:a:0 output/video0_reconstructed_audio.mp4 -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
