{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from dist_yolo.dist_yolo import DistYOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_yolo = DistYOLO()\n",
    "dist_yolo.load_model('./dist_yolo/trained_final (2).h5')\n",
    "# image = Image.open(input_image_path)\n",
    "# pred = dist_yolo.detect(image)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 739ms/step\n"
     ]
    }
   ],
   "source": [
    "input_image_path = r\"./images/input1.png\"\n",
    "img = Image.open(input_image_path)\n",
    "# result = dist_yolo.detect_image(img)\n",
    "# result.show()\n",
    "result = dist_yolo.detect(img)\n",
    "dets = list(zip(result[0], result[1], result[2], result[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bounding box\n",
    "output_image = Image.open(input_image_path)\n",
    "draw = ImageDraw.Draw(output_image)\n",
    "for p in dets:\n",
    "    if p[1] != 1 and p[1] != 2 and p[1] != 3:\n",
    "        continue\n",
    "    \n",
    "    draw.rectangle(((p[0][0], p[0][1]), (p[0][2], p[0][3])))\n",
    "    draw.text(((p[0][0] + p[0][2]) / 2, (p[0][1] + p[0][3]) / 2), f'{p[3]}')\n",
    "\n",
    "# output_image.save('output.jpg', 'JPEG')\n",
    "output_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread()\n",
    "Image.fromarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Video frame count = 60\n",
      "Number of CPU: 8\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Bounding Box to Raw Dist-YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"video/video3.mp4\"\n",
    "output_file_name = \"output/video3_3_output.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "# Draw bounding box to video\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "with open('output/dist_yolo_output_video3_3.json') as f:\n",
    "    dyo = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "try:\n",
    "    while proc_frames < len(dyo):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        for i in dyo[proc_frames]:\n",
    "            cv2.rectangle(im, (i[0], i[1]), (i[2], i[3]), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{int(i[6])}', ((i[0] + i[2])//2, (i[1]+i[3])//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    print(error)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kalman_tracking.sort import Sort\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"video/video3.mp4\"\n",
    "output_file_name = \"output/video3_3_output_tracked.mp4\"\n",
    "output_state_file_name = \"output/video3_3_states.json\"\n",
    "\n",
    "sort = Sort(max_age=10, iou_threshold=0.3, zc=320)\n",
    "\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "with open('output/dist_yolo_output_video3_3.json') as f:\n",
    "    dyo = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "states = []\n",
    "try:\n",
    "    while proc_frames < len(dyo):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        d = dyo[proc_frames]\n",
    "        d_converted = []\n",
    "        for x in d:\n",
    "            d_converted.append([x[0], x[1], x[2], x[3], x[6]])\n",
    "        d_converted = np.array(d_converted)\n",
    "\n",
    "        # tracking\n",
    "        if len(d_converted) > 0:\n",
    "            xs, xrs = sort.update(d_converted)\n",
    "        else:\n",
    "            xs, xrs = sort.update()\n",
    "\n",
    "        temp = []\n",
    "        for (x, xr) in zip(xs, xrs):\n",
    "            temp.append(xr.tolist() + [int(x[-1])])\n",
    "            cv2.rectangle(im, (int(x[0]), int(x[1])), (int(x[2]), int(x[3])), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{int(x[4])} ({int(xr[0])},{int(xr[1])},{int(xr[2])})', (int((x[0] + x[2])//2), int((x[1] + x[3])//2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        states.append(temp)\n",
    "\n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    print(error.with_traceback())\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "\n",
    "with open(output_state_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump({ \"states\": states }, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 87279.722020\n",
      "         Iterations: 3\n",
      "         Function evaluations: 666\n",
      "         Gradient evaluations: 47\n",
      "time: 0.17644095420837402\n",
      "alpha 3.428334092220827\n",
      "beta -11.648205071100843\n",
      "gamma -1.512388108766532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1698: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_cg(f, x0, args, fprime, callback=callback, **opts)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mygplvm.reconstruction import Reconstruction\n",
    "\n",
    "sdfs = []\n",
    "sdf_names = ['Bus', 'Jeep', 'Pickup', 'Sedan', 'Suv']\n",
    "voxel_resolution = 60\n",
    "dct_resolution = 25\n",
    "for name in sdf_names:\n",
    "    sdfs.append(np.load(f'./mygplvm/objs/{name}_SDF_{voxel_resolution}x{voxel_resolution}x{voxel_resolution}.npy'))\n",
    "\n",
    "rec = Reconstruction(voxel_resolution=voxel_resolution, dct_resolution=dct_resolution)\n",
    "rec.fit_from_sdf(sdfs=sdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, sin, pi\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "output_file_name = 'output/video3_3_output_reconstructed.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(30)\n",
    "width, height = (\n",
    "    int(1280),\n",
    "    int(720)\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "with open('output/video3_3_states.json') as f:\n",
    "    states = json.load(f)['states']\n",
    "\n",
    "try:\n",
    "    for i, state in enumerate(states):\n",
    "        scene = pyrender.Scene(ambient_light=[0.6, 0.6, 0.6], bg_color=[1.0, 1.0, 1.0])\n",
    "        state_multiplier = 6\n",
    "        for vehicle in state:\n",
    "            mc_mesh = rec.reconstruct_from_x([-10, -3])\n",
    "            mesh_pyrender = pyrender.Mesh.from_trimesh(mc_mesh, smooth=True)\n",
    "            sudut = pi / 2\n",
    "            mesh_pose = np.array([\n",
    "                [cos(sudut), 0, sin(sudut), vehicle[0] * state_multiplier],\n",
    "                [0, 1, 0, 0],\n",
    "                [-sin(sudut), 0, cos(sudut), -vehicle[2] * state_multiplier],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            scene.add(mesh_pyrender, pose=mesh_pose)\n",
    "\n",
    "        camera_pose = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 62],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        light_pose = np.array([\n",
    "            [1, 0, 0, 62],\n",
    "            [0, 1, 0, 62],\n",
    "            [0, 0, 1, 62],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        pl = pyrender.PointLight(color=[1.0, 1.0, 1.0], intensity=50000)\n",
    "        pc = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1280/720)\n",
    "        scene.add(pl, pose=light_pose)\n",
    "        scene.add(pc, pose=camera_pose)\n",
    "\n",
    "        r = pyrender.OffscreenRenderer(1280, 720)\n",
    "        color, _ = r.render(scene)\n",
    "        # plt.figure(figsize=(8,8)), plt.imshow(color)\n",
    "        out.write(color)\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    print(error.with_traceback())\n",
    "    out.release()\n",
    "\n",
    "out.release()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
