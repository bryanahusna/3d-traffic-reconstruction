{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from dist_yolo.dist_yolo import DistYOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_yolo = DistYOLO()\n",
    "dist_yolo.load_model('./dist_yolo/trained_final (2).h5')\n",
    "# image = Image.open(input_image_path)\n",
    "# pred = dist_yolo.detect(image)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 739ms/step\n"
     ]
    }
   ],
   "source": [
    "input_image_path = r\"./images/input1.png\"\n",
    "img = Image.open(input_image_path)\n",
    "# result = dist_yolo.detect_image(img)\n",
    "# result.show()\n",
    "result = dist_yolo.detect(img)\n",
    "dets = list(zip(result[0], result[1], result[2], result[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bounding box\n",
    "output_image = Image.open(input_image_path)\n",
    "draw = ImageDraw.Draw(output_image)\n",
    "for p in dets:\n",
    "    if p[1] != 1 and p[1] != 2 and p[1] != 3:\n",
    "        continue\n",
    "    \n",
    "    draw.rectangle(((p[0][0], p[0][1]), (p[0][2], p[0][3])))\n",
    "    draw.text(((p[0][0] + p[0][2]) / 2, (p[0][1] + p[0][3]) / 2), f'{p[3]}')\n",
    "\n",
    "# output_image.save('output.jpg', 'JPEG')\n",
    "output_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Bounding Box to Raw Dist-YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"video/video3.mp4\"\n",
    "output_file_name = \"output/video3_3_output.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "# Draw bounding box to video\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "with open('output/dist_yolo_output_video3_3.json') as f:\n",
    "    dyo = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "try:\n",
    "    while proc_frames < len(dyo):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        for i in dyo[proc_frames]:\n",
    "            cv2.rectangle(im, (i[0], i[1]), (i[2], i[3]), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{int(i[6])}', ((i[0] + i[2])//2, (i[1]+i[3])//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    print(error)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bryan\\TA\\Integrated\\kalman_tracking\\sort.py:74: RuntimeWarning: invalid value encountered in sqrt\n",
      "  w = np.sqrt(x[3] * x[4])\n"
     ]
    }
   ],
   "source": [
    "from kalman_tracking.sort import Sort\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"video/video1.mp4\"\n",
    "output_file_name = \"output/video1_3_output_tracked.mp4\"\n",
    "output_state_file_name = \"output/video1_3_states.json\"\n",
    "\n",
    "sort = Sort(max_age=10, iou_threshold=0.3, zc=320)\n",
    "\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "with open('output/dist_yolo_output_video1_3.json') as f:\n",
    "    dyo = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "states = []\n",
    "color_mapping = {}\n",
    "try:\n",
    "    while proc_frames < len(dyo):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        d = dyo[proc_frames]\n",
    "        d_converted = []\n",
    "        for x in d:\n",
    "            d_converted.append([x[0], x[1], x[2], x[3], x[6]])\n",
    "        d_converted = np.array(d_converted)\n",
    "\n",
    "        # tracking\n",
    "        if len(d_converted) > 0:\n",
    "            xs, xrs = sort.update(d_converted)\n",
    "        else:\n",
    "            xs, xrs = sort.update()\n",
    "\n",
    "        temp = []\n",
    "        for (x, xr) in zip(xs, xrs):\n",
    "            vehicle_id = int(x[-1])\n",
    "            if vehicle_id not in color_mapping:\n",
    "                bounding_rect = im[int(x[1]):int(x[3]), int(x[0]):int(x[2])]\n",
    "                bgr_color = np.average(np.average(bounding_rect, axis=0), axis=0)\n",
    "\n",
    "                hsv_color = cv2.cvtColor(np.array([[bgr_color]]).astype(np.uint8), cv2.COLOR_BGR2HSV)\n",
    "                hsv_color[:, :, 1] = np.array(min(hsv_color[:, :, 1] * 1.5, 255)).astype(np.uint8)\n",
    "                hsv_color[:, :, 2] *= np.array(min(hsv_color[:, :, 2] * 1, 255)).astype(np.uint8)\n",
    "                bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)[0, 0]\n",
    "\n",
    "                rgb_color = [int(bgr_color[2]), int(bgr_color[1]), int(bgr_color[0])]\n",
    "                color_mapping[vehicle_id] = rgb_color\n",
    "\n",
    "            temp.append(xr.tolist() + [int(x[-1]), color_mapping[vehicle_id]])\n",
    "            cv2.rectangle(im, (int(x[0]), int(x[1])), (int(x[2]), int(x[3])), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{int(x[4])} ({int(xr[0])},{int(xr[1])},{int(xr[2])})', (int((x[0] + x[2])//2), int((x[1] + x[3])//2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        states.append(temp)\n",
    "\n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(error.with_traceback())\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "\n",
    "with open(output_state_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump({ \"states\": states }, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 92231.596252\n",
      "         Iterations: 3\n",
      "         Function evaluations: 796\n",
      "         Gradient evaluations: 56\n",
      "time: 0.20706391334533691\n",
      "alpha 1.172870663390303\n",
      "beta 0.6048697071085747\n",
      "gamma 0.9999992562935022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1698: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_cg(f, x0, args, fprime, callback=callback, **opts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 51.15093994,   7.46380615],\n",
       "       [-42.88323975,  12.87239742],\n",
       "       [ 13.78208542,  -2.41257048],\n",
       "       [-13.68172067, -10.06780717],\n",
       "       [ -8.36767489,  -7.85581305]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mygplvm.reconstruction import Reconstruction\n",
    "\n",
    "sdfs = []\n",
    "sdf_names = ['Bus', 'Jeep', 'Pickup', 'Sedan', 'Suv']\n",
    "voxel_resolution = 64\n",
    "dct_resolution = 25\n",
    "for name in sdf_names:\n",
    "    sdfs.append(np.load(f'./mygplvm/objs2/{name}_SDF_{voxel_resolution}x{voxel_resolution}x{voxel_resolution}.npy'))\n",
    "\n",
    "rec = Reconstruction(voxel_resolution=voxel_resolution, dct_resolution=dct_resolution)\n",
    "rec.fit_from_sdf(sdfs=sdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "from math import cos, sin, pi\n",
    "import json\n",
    "import cv2\n",
    "import trimesh\n",
    "\n",
    "output_file_name = 'output/video1_3_output_reconstructed.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(30)\n",
    "width, height = (\n",
    "    int(1280),\n",
    "    int(720)\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(output_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "with open('output/video1_3_states.json') as f:\n",
    "    states = json.load(f)['states']\n",
    "\n",
    "try:\n",
    "    for i, state in enumerate(states):\n",
    "        if (i == 10): break\n",
    "        scene = pyrender.Scene(ambient_light=[0.6, 0.6, 0.6], bg_color=[1.0, 1.0, 1.0])\n",
    "        state_multiplier = 6\n",
    "        for vehicle in state:\n",
    "            mc_mesh = rec.reconstruct_from_x([-13.68172067, -10.06780717])\n",
    "            # for facet in mc_mesh.facets:\n",
    "            #     mc_mesh.visual.face_colors[facet] = vehicle[10] + [255]\n",
    "            mc_mesh.visual.vertex_colors = vehicle[10] + [255]\n",
    "\n",
    "            mesh_pyrender = pyrender.Mesh.from_trimesh(mc_mesh, smooth=False)\n",
    "            sudut = 0\n",
    "            mesh_pose = np.array([\n",
    "                [cos(sudut), 0, sin(sudut), vehicle[0] * state_multiplier],\n",
    "                [0, 1, 0, 0],\n",
    "                [-sin(sudut), 0, cos(sudut), -vehicle[2] * state_multiplier],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            scene.add(mesh_pyrender, pose=mesh_pose)\n",
    "\n",
    "        camera_pose = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 62],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        light_pose = np.array([\n",
    "            [1, 0, 0, 62],\n",
    "            [0, 1, 0, 62],\n",
    "            [0, 0, 1, 62],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "        pl = pyrender.PointLight(color=[1.0, 1.0, 1.0], intensity=50000)\n",
    "        pc = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1280/720)\n",
    "        scene.add(pl, pose=light_pose)\n",
    "        scene.add(pc, pose=camera_pose)\n",
    "\n",
    "        r = pyrender.OffscreenRenderer(1280, 720)\n",
    "        color, _ = r.render(scene)\n",
    "        # plt.figure(figsize=(8,8)), plt.imshow(color)\n",
    "        out.write(color)\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    out.release()\n",
    "    print(error.with_traceback())\n",
    "\n",
    "out.release()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
