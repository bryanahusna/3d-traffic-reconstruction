{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov9c.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Bryan\\TA\\Integrated\\images\\input7.png: 384x640 9 cars, 801.2ms\n",
      "Speed: 4.0ms preprocess, 801.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model.predict('./images/input7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218660593032837"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(results[0].boxes.conf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting using GPU...\n",
      "\n",
      "0: 384x640 8 cars, 106.9ms\n",
      "Speed: 3.1ms preprocess, 106.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.5ms\n",
      "Speed: 3.0ms preprocess, 103.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 104.1ms\n",
      "Speed: 2.0ms preprocess, 104.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.1ms\n",
      "Speed: 2.0ms preprocess, 103.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 105.1ms\n",
      "Speed: 1.9ms preprocess, 105.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.1ms\n",
      "Speed: 2.0ms preprocess, 103.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.0ms\n",
      "Speed: 3.1ms preprocess, 103.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.6ms\n",
      "Speed: 2.0ms preprocess, 103.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 103.1ms\n",
      "Speed: 3.0ms preprocess, 103.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 105.1ms\n",
      "Speed: 2.2ms preprocess, 105.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 102.0ms\n",
      "Speed: 2.0ms preprocess, 102.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 105.1ms\n",
      "Speed: 2.0ms preprocess, 105.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 108.0ms\n",
      "Speed: 2.0ms preprocess, 108.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 106.6ms\n",
      "Speed: 4.0ms preprocess, 106.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 104.0ms\n",
      "Speed: 2.1ms preprocess, 104.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 104.0ms\n",
      "Speed: 2.0ms preprocess, 104.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 103.7ms\n",
      "Speed: 2.1ms preprocess, 103.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 108.1ms\n",
      "Speed: 3.0ms preprocess, 108.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 107.1ms\n",
      "Speed: 3.0ms preprocess, 107.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 107.1ms\n",
      "Speed: 3.1ms preprocess, 107.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 108.0ms\n",
      "Speed: 2.0ms preprocess, 108.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 108.0ms\n",
      "Speed: 2.0ms preprocess, 108.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.8ms\n",
      "Speed: 2.0ms preprocess, 108.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.0ms\n",
      "Speed: 1.6ms preprocess, 108.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 109.1ms\n",
      "Speed: 2.1ms preprocess, 109.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 109.1ms\n",
      "Speed: 2.0ms preprocess, 109.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 109.3ms\n",
      "Speed: 2.0ms preprocess, 109.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 107.9ms\n",
      "Speed: 2.0ms preprocess, 107.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 110.0ms\n",
      "Speed: 2.0ms preprocess, 110.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 107.0ms\n",
      "Speed: 2.0ms preprocess, 107.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 109.4ms\n",
      "Speed: 2.0ms preprocess, 109.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 112.0ms\n",
      "Speed: 2.0ms preprocess, 112.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.7ms\n",
      "Speed: 2.0ms preprocess, 108.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 107.4ms\n",
      "Speed: 2.0ms preprocess, 107.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 107.4ms\n",
      "Speed: 2.2ms preprocess, 107.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.5ms\n",
      "Speed: 2.0ms preprocess, 108.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.4ms\n",
      "Speed: 2.0ms preprocess, 108.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 106.4ms\n",
      "Speed: 3.0ms preprocess, 106.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.3ms\n",
      "Speed: 3.2ms preprocess, 108.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 107.4ms\n",
      "Speed: 2.0ms preprocess, 107.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 109.1ms\n",
      "Speed: 2.0ms preprocess, 109.1ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 109.0ms\n",
      "Speed: 2.0ms preprocess, 109.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 108.2ms\n",
      "Speed: 3.0ms preprocess, 108.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 109.0ms\n",
      "Speed: 1.9ms preprocess, 109.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 109.0ms\n",
      "Speed: 2.9ms preprocess, 109.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Load YOLOv9\n",
    "# Fail, cuda not yet implemented in yolov9\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    model = YOLO(\"yolov9c.pt\").to('cuda')\n",
    "    print('Detecting using GPU...')\n",
    "else:\n",
    "    model = YOLO(\"yolov9c.pt\").to('cpu')\n",
    "    print('Detecting using CPU...')\n",
    "\n",
    "# model = YOLO(\"yolov9c.pt\").to('cuda:0')\n",
    "# print('Detecting using GPU...')\n",
    "\n",
    "# Read video file\n",
    "video_name = 'video1'\n",
    "input_file_name = f'video/{video_name}.mp4'\n",
    "cap = cv2.VideoCapture(input_file_name)\n",
    "\n",
    "# get height, width and frame count of the video\n",
    "width, height = (\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    )\n",
    "no_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "proc_frames = 0\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "# fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "# out = cv2.VideoWriter()\n",
    "# output_file_name = \"output_multi.mp4\"\n",
    "# out.open(\"output_{}.mp4\".format(group_number), fourcc, fps, (width, height), True)\n",
    "\n",
    "frames = []\n",
    "frames_detections = []\n",
    "try:\n",
    "    for d in range(no_of_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        result = model.predict(frame)[0]\n",
    "        frame_detections = []\n",
    "        for d, box in enumerate(result.boxes):\n",
    "            accepted_class_names = ['car', 'bus', 'truck']\n",
    "            class_index = int(result.boxes.cls[d])\n",
    "            conf = float(result.boxes.conf[d])\n",
    "            if result.names[class_index] not in accepted_class_names:\n",
    "                continue\n",
    "            frame_detections.append(result.boxes.xywh[d].tolist() +  [class_index, conf])\n",
    "        frames_detections.append(frame_detections)\n",
    "except:\n",
    "    pass\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    # out.release()\n",
    "\n",
    "# Add to frames detections\n",
    "with open(f'output/{video_name}_yolov9.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({ \"final_frames_detections\": frames_detections }, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# frames_detections.append(frame_jump_unit * group_number + proc_frames)\n",
    "\n",
    "# Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "# for i in bboxes:\n",
    "#     cv2.rectangle(im, (i[0], i[1]), (i[2], i[3]), (0, 255, 0), 3)\n",
    "\n",
    "# write the frame\n",
    "# out.write(im)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "# out.release()\n",
    "\n",
    "# with open(f'output/dist_yolo_{group_number}.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump({ \"frames_detections\": frames_detections }, f, ensure_ascii=False, indent=4)\n",
    "# out.open(\"output_{}.mp4\".format(group_number), fourcc, fps, (width, height), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "yolov9_file_name = f'output/{video_name}_yolov9.mp4'\n",
    "\n",
    "# Draw bounding box to video\n",
    "cap = cv2.VideoCapture(input_file_name)\n",
    "with open(f'output/{video_name}_yolov9.json') as f:\n",
    "    detections = json.load(f)['final_frames_detections']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width, height = (\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    ")\n",
    "out = cv2.VideoWriter()\n",
    "out.open(yolov9_file_name, fourcc, fps, (width, height), True)\n",
    "\n",
    "proc_frames = 0\n",
    "try:\n",
    "    while proc_frames < len(detections):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        im = frame\n",
    "        # Loop through list (if empty this will be skipped) and overlay green bboxes\n",
    "        for d in detections[proc_frames]:\n",
    "            cv2.rectangle(im, (int(d[0] - d[2]/2), int(d[1] - d[3]/2)), (int(d[0] + d[2]/2), int(d[1] + d[3]/2)), (0, 255, 0), 3)\n",
    "            cv2.putText(im, f'{d[5]:.2f}', (int(d[0]), int(d[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # write the frame\n",
    "        out.write(im)\n",
    "\n",
    "        proc_frames += 1\n",
    "except Exception as error:\n",
    "    # Release resources\n",
    "    print(error)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "out.release()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
